"""
Î²[l] âˆˆ (-Ï€, Ï€], âˆ€ l âˆˆ [L].
"""
function solveFIDFTÎ²problem( Î¾s::Vector{T},
                            Î»s::Vector{T},
                            Î±s::Vector{T},
                            Îºs::Vector{T},
                            S_ğ“Ÿ::Vector{Complex{T}},
                            ğ“Ÿ,
                            Î²_initial::Vector{T};
                            max_iter::Int = 90,
                            verbose_flag::Bool = false,
                            max_iter_tCG = 30,
                            Ï_lower_acceptance = 0.2, # recommended to be less than 0.25
                            Ï_upper_acceptance = 5.0,
                            minimum_TR_radius::T = 1e-3,
                            maximum_TR_radius::T = 10.0,
                            norm_df_tol = 1e-5,
                            objective_tol = 1e-5,
                            avg_Î”f_tol = 0.0, #1e-12 #1e-5
                            avg_Î”f_window = 10,
                            max_idle_update_count = 50,
                            g::Function = pp->one(T), # use Euclidean metric.
                            ğ‘Ÿ = 1e-2)::Tuple{Vector{T},Vector{T},Vector{T},Int} where T <: Real

    # set up.
    L = length(Î²_initial)
    @assert length(Î¾s) == L == length(Î»s) == length(Îºs) == length(Î±s)

    # prepare initial guess.
    N_vars = length(Î²_initial)


    # set up cost function.
    f = bb->evalFIDFTphasecostfunc(bb, Î±s, Î»s, Îºs, Î¾s, ğ“Ÿ, S_ğ“Ÿ)

    df_Euc = aa->ForwardDiff.gradient(f, aa)

    # tell optimizer to use hessian approx.
    H = zeros(T, N_vars, N_vars)

    # retraction.
    â„œ = circleretractionwithproject

    ## configuration for the trust-region subproblem.
    TR_config = TrustRegionConfigType(  minimum_TR_radius,
                                        maximum_TR_radius,
                                        max_iter_tCG,
                                        verbose_flag,
                                        Ï_lower_acceptance,
                                        Ï_upper_acceptance)

    opt_config = OptimizationConfigType( max_iter,
                                            verbose_flag,
                                            norm_df_tol,
                                            objective_tol,
                                            avg_Î”f_tol,
                                            avg_Î”f_window,
                                            max_idle_update_count,
                                            ğ‘Ÿ )

    ## Run scheme.
    p_star, f_p_array, norm_df_array,
        num_iters = engineArray(f,
                            df_Euc,
                            Î²_initial,
                            copy(Î²_initial),
                            TR_config,
                            opt_config,
                            H,
                            â„œ;
                            ğ‘” = g)
    #
    return p_star, f_p_array, norm_df_array, num_iters
end



# RMO is Riemmanian manifold optimization.
function solveFIDFTÎ±Î²problemRMO( Î¾s::Vector{T},
                            Î»s::Vector{T},
                            S_ğ“Ÿ::Vector{Complex{T}},
                            ğ“Ÿ,
                            Î±_values_initial::Vector{T},
                            Î²_initial::Vector{T},
                            Î±_max::T;
                            max_iters_RMO::Int = 90,
                            verbose_flag::Bool = false,
                            max_iter_tCG = 30,
                            Ï_lower_acceptance = 0.2, # recommended to be less than 0.25
                            Ï_upper_acceptance = 5.0,
                            minimum_TR_radius::T = 1e-3,
                            maximum_TR_radius::T = 10.0,
                            norm_df_tol = 1e-5,
                            objective_tol = 1e-5,
                            avg_Î”f_tol = 0.0, #1e-12 #1e-5
                            avg_Î”f_window = 10,
                            max_idle_update_count = 50,
                            g::Function = pp->one(T), # use Euclidean metric.
                            ğ‘Ÿ = 1e-2,
                            Ïµ_retraction = 1e-9) where T <: Real

    # set up.
    L = length(Î²_initial)
    @assert length(Î¾s) == L == length(Î»s)

    N_pairs = length(Î±_values_initial)

    # prepare initial guess.
    p_initial = [Î±_values_initial; Î²_initial]
    N_vars = length(p_initial)


    # set up cost function.
    f = pp->evalFIDFTÎ±Î²costfunc(pp, Î»s, Î¾s, ğ“Ÿ, S_ğ“Ÿ)

    #df_Euc = aa->ForwardDiff.gradient(f, aa)

    Î±s_persist, Î²s_persist, âˆ‚ğ“›_âˆ‚Î²_eval_persist, âˆ‚ğ“›_âˆ‚Î±_eval_persist,
            âˆ‚ğ“›_âˆ‚a_eval_persist, diff_persist = setupFTFIDÎ±Î²ğ“›(N_pairs, L, length(S_ğ“Ÿ), one(T))

    df_Euc = pp->evalFIDFTÎ±Î²costfuncgradient!(Î±s_persist,
                    Î²s_persist, âˆ‚ğ“›_âˆ‚Î²_eval_persist,
                    âˆ‚ğ“›_âˆ‚Î±_eval_persist, âˆ‚ğ“›_âˆ‚a_eval_persist,
                    diff_persist,
                    pp, Î»s, Î¾s, ğ“Ÿ, S_ğ“Ÿ)

    # tell optimizer to use hessian approx.
    H = zeros(T, N_vars, N_vars)

    # set up retractions.
      function â„œnD( p::Vector{T},
                  X::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FIDnDretraction(p, X, t, N_pairs, Î±_max; Ïµ = Ïµ_retraction)
      end

      function â„œnD( p::Vector{T},
                  X::Vector{T},
                  Y::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FIDnDretraction(p, X, Y, t, N_pairs, Î±_max; Ïµ = Ïµ_retraction)
      end

      function â„œ1D( p::Vector{T},
                  X::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FID1Dretraction(p, X, t, N_pairs, Î±_max)
      end

      function â„œ1D( p::Vector{T},
                  X::Vector{T},
                  Y::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FID1Dretraction(p, X, Y, t, N_pairs, Î±_max)
      end

      â„œ = â„œnD
      if length(Î±_values_initial) == 1
          â„œ = â„œ1D
      end

    ## configuration for the trust-region subproblem.
    TR_config = TrustRegionConfigType(  minimum_TR_radius,
                                        maximum_TR_radius,
                                        max_iter_tCG,
                                        verbose_flag,
                                        Ï_lower_acceptance,
                                        Ï_upper_acceptance)

    opt_config = OptimizationConfigType( max_iters_RMO,
                                            verbose_flag,
                                            norm_df_tol,
                                            objective_tol,
                                            avg_Î”f_tol,
                                            avg_Î”f_window,
                                            max_idle_update_count,
                                            ğ‘Ÿ )

    ## Run scheme.
    p_star, f_p_array, norm_df_array,
        num_iters = engineArray(f,
                            df_Euc,
                            p_initial,
                            copy(p_initial),
                            TR_config,
                            opt_config,
                            H,
                            â„œ;
                            ğ‘” = g)
    #
    return p_star, f_p_array, norm_df_array, num_iters,
            f, df_Euc
end

function solveFIDFTÎ±Î²problemPSO( Î¾s::Vector{T},
                            Î»s::Vector{T},
                            S_ğ“Ÿ::Vector{Complex{T}},
                            ğ“Ÿ,
                            Î±_values_initial::Vector{T},
                            Î²_initial::Vector{T};
                            max_iters_PSO::Int = 90,
                            N_particles = 3,
                            Ïµ_retraction = 1e-9) where T <: Real

    # set up.
    L = length(Î²_initial)
    @assert length(Î¾s) == L == length(Î»s)

    N_pairs = length(Î±_values_initial)

    # prepare initial guess.
    p_initial = [Î±_values_initial; Î²_initial]

    # set up original problem's objective function.
    f = pp->evalFIDFTÎ±Î²costfunc(pp, Î»s, Î¾s, ğ“Ÿ, S_ğ“Ÿ)

    # set up retractions.
      function â„œnD( p::Vector{T},
                  X::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FIDnDretraction(p, X, t, N_pairs, Î±_max; Ïµ = Ïµ_retraction)
      end

      function â„œnD( p::Vector{T},
                  X::Vector{T},
                  Y::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FIDnDretraction(p, X, Y, t, N_pairs, Î±_max; Ïµ = Ïµ_retraction)
      end

      function â„œ1D( p::Vector{T},
                  X::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FID1Dretraction(p, X, t, N_pairs, Î±_max)
      end

      function â„œ1D( p::Vector{T},
                  X::Vector{T},
                  Y::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FID1Dretraction(p, X, Y, t, N_pairs, Î±_max)
      end

      â„œ = â„œnD
      if length(Î±_values_initial) == 1
          â„œ = â„œ1D
      end

    # set up PSO's objective function.
    costfunc = XX->f(â„œ(p_initial, XX, one(T)))

    # initial guess.
    x0 = zeros(T, length(p_initial))

    # optimize for the tangent vector that yields the least cost.
    # Unconstrained optimization.
    op = Optim.Options( iterations = max_iters_PSO,
                             store_trace = false,
                             show_trace = false)

    swarm = Optim.ParticleSwarm(; lower = [],
                    upper = [],
                    n_particles = N_particles)
    #
    results = Optim.optimize(costfunc,
                    x0, swarm, op)

    x_star = results.minimizer
    p_star = â„œ(p_initial, x_star, one(T))

    return p_star
end

# # hybrid between PSO and Riemannian manifold optimization.
# # RMO is Riemmanian manifold optimization.
# RMO is Riemmanian manifold optimization.
function solveFIDFTÎ±Î²problemhybrid( Î¾s::Vector{T},
                            Î»s::Vector{T},
                            S_ğ“Ÿ::Vector{Complex{T}},
                            ğ“Ÿ,
                            Î±_values_initial::Vector{T},
                            Î²_initial::Vector{T},
                            Î±_max::T;
                            minimum_TR_radius = 1e-3 .* ones(T, 3),
                            iters_RMOs = 100 .* ones(Int, 3),
                            N_particles = 4 .* ones(Int, 3),
                            iters_PSOs = 1000 .* ones(Int, 3),
                            verbose_flag::Bool = false,
                            max_iter_tCG = 30,
                            Ï_lower_acceptance = 0.2, # recommended to be less than 0.25
                            Ï_upper_acceptance = 5.0,
                            maximum_TR_radius::T = 10.0,
                            norm_df_tol = 1e-5,
                            objective_tol = 1e-5,
                            avg_Î”f_tol = 0.0, #1e-12 #1e-5
                            avg_Î”f_window = 10,
                            max_idle_update_count = 50,
                            g::Function = pp->one(T), # use Euclidean metric.
                            ğ‘Ÿ = 1e-2,
                            Ïµ_retraction = 1e-9) where T <: Real

    # set up.
    L = length(Î²_initial)
    @assert length(Î¾s) == L == length(Î»s)

    N_pairs = length(Î±_values_initial)

    # prepare initial guess.
    p_initial = [Î±_values_initial; Î²_initial]
    N_vars = length(p_initial)


    # set up cost function.
    f = pp->evalFIDFTÎ±Î²costfunc(pp, Î»s, Î¾s, ğ“Ÿ, S_ğ“Ÿ)

    #df_Euc = aa->ForwardDiff.gradient(f, aa)

    Î±s_persist, Î²s_persist, âˆ‚ğ“›_âˆ‚Î²_eval_persist, âˆ‚ğ“›_âˆ‚Î±_eval_persist,
            âˆ‚ğ“›_âˆ‚a_eval_persist, diff_persist = setupFTFIDÎ±Î²ğ“›(N_pairs, L, length(S_ğ“Ÿ), one(T))

    df_Euc = pp->evalFIDFTÎ±Î²costfuncgradient!(Î±s_persist,
                    Î²s_persist, âˆ‚ğ“›_âˆ‚Î²_eval_persist,
                    âˆ‚ğ“›_âˆ‚Î±_eval_persist, âˆ‚ğ“›_âˆ‚a_eval_persist,
                    diff_persist,
                    pp, Î»s, Î¾s, ğ“Ÿ, S_ğ“Ÿ)

    # tell optimizer to use hessian approx.
    H = zeros(T, N_vars, N_vars)

    # set up retractions.
      function â„œnD( p::Vector{T},
                  X::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FIDnDretraction(p, X, t, N_pairs, Î±_max; Ïµ = Ïµ_retraction)
      end

      function â„œnD( p::Vector{T},
                  X::Vector{T},
                  Y::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FIDnDretraction(p, X, Y, t, N_pairs, Î±_max; Ïµ = Ïµ_retraction)
      end

      function â„œ1D( p::Vector{T},
                  X::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FID1Dretraction(p, X, t, N_pairs, Î±_max)
      end

      function â„œ1D( p::Vector{T},
                  X::Vector{T},
                  Y::Vector{T},
                  t::T2)::Vector{T2} where {T <: Real, T2 <: Real}

          return FID1Dretraction(p, X, Y, t, N_pairs, Î±_max)
      end

      â„œ = â„œnD
      if length(Î±_values_initial) == 1
          â„œ = â„œ1D
      end

    ## configuration for the trust-region subproblem.
    TR_config = TrustRegionConfigType(  minimum_TR_radius[1],
                                        maximum_TR_radius,
                                        max_iter_tCG,
                                        verbose_flag,
                                        Ï_lower_acceptance,
                                        Ï_upper_acceptance)

    opt_config = OptimizationConfigType( iters_RMOs[1],
                                            verbose_flag,
                                            norm_df_tol,
                                            objective_tol,
                                            avg_Î”f_tol,
                                            avg_Î”f_window,
                                            max_idle_update_count,
                                            ğ‘Ÿ )
    #


    N_epochs = length(iters_PSOs)
    @assert length(minimum_TR_radius) == length(iters_RMOs) == length(N_particles) == N_epochs

    # set up PSO's objective function.
    p_PSO_persist = Vector{T}(undef, N_vars)
    costfunc = XX->f(â„œ(p_PSO_persist, XX, one(T)))

    # invariant objects.
    x0 = zeros(T, N_vars)
    X0 = zeros(T, N_vars)

    # outputs.
    p_star_PSOs = Vector{Vector{T}}(undef, N_epochs)
    p_star_RMOs = Vector{Vector{T}}(undef, N_epochs)

    #### first epoch.
    ## Run PSO.
    # update costfunc.
    p_PSO_persist[:] = p_initial



    # optimize for the tangent vector that yields the least cost.
    # Unconstrained optimization.
    op = Optim.Options( iterations = iters_PSOs[1],
                             store_trace = false,
                             show_trace = false)

    swarm = Optim.ParticleSwarm(; lower = [],
                    upper = [],
                    n_particles = N_particles[1])
    #
    results = Optim.optimize(costfunc,
                    x0, swarm, op)

    x_star = results.minimizer
    p_star_PSOs[1] = â„œ(p_PSO_persist, x_star, one(T))

    ## Run RMO.
    TR_config.minimum_TR_radius = minimum_TR_radius[1]
    opt_config.max_iter = iters_RMOs[1]

    p_star_RMOs[1], _, _, _ = engineArray(f,
                                df_Euc,
                                copy(p_star_PSOs[1]),
                                X0,
                                TR_config,
                                opt_config,
                                H,
                                â„œ;
                                ğ‘” = g)

    for k = 2:N_epochs

        # debug.
        println()
        println("Starting epoch ", k)
        println()
        # end debug.

        ## Run PSO.
        # update PSO costfunc.
        p_PSO_persist[:] = p_star_RMOs[k-1]

        # optimize for the tangent vector that yields the least cost.
        # Unconstrained optimization.
        op = Optim.Options( iterations = iters_PSOs[k],
                                 store_trace = false,
                                 show_trace = false)

        swarm = Optim.ParticleSwarm(; lower = [],
                        upper = [],
                        n_particles = N_particles[k])
        #
        results = Optim.optimize(costfunc,
                        x0, swarm, op)

        x_star = results.minimizer
        p_star_PSOs[k] = â„œ(p_PSO_persist, x_star, one(T))

        ## Run RMO.
        TR_config.minimum_TR_radius = minimum_TR_radius[k]
        opt_config.max_iter = iters_RMOs[k]

        p_star_RMOs[k], _, _, _ = engineArray(f,
                                    df_Euc,
                                    copy(p_star_PSOs[k]),
                                    X0,
                                    TR_config,
                                    opt_config,
                                    H,
                                    â„œ;
                                    ğ‘” = g)
    #
    end

    p_star = p_star_RMOs[end]

    return p_star, p_star_PSOs, p_star_RMOs, f, df_Euc
end
