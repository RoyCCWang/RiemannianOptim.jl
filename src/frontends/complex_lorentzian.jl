"""
Œ≤[l] ‚àà (-œÄ, œÄ], ‚àÄ l ‚àà [L].
"""
function solvecLŒ≤problem( Œ©s::Vector{T},
                            Œª::T,
                            Œ±s::Vector{T},
                            S_U::Vector{Complex{T}},
                            U,
                            Œ≤_initial::Vector{T};
                            max_iter::Int = 90,
                            verbose_flag::Bool = false,
                            max_iter_tCG = 30,
                            œÅ_lower_acceptance = 0.2, # recommended to be less than 0.25
                            œÅ_upper_acceptance = 5.0,
                            minimum_TR_radius::T = 1e-3,
                            maximum_TR_radius::T = 10.0,
                            norm_df_tol = 1e-5,
                            objective_tol = 1e-5,
                            avg_Œîf_tol = 0.0, #1e-12 #1e-5
                            avg_Œîf_window = 10,
                            max_idle_update_count = 50,
                            g::Function = pp->one(T), # use Euclidean metric.
                            ùëü = 1e-2)::Tuple{Vector{T},Vector{T},Vector{T},Int} where T <: Real

    # set up.
    L = length(Œ≤_initial)
    @assert length(Œ©s) == L == length(Œ±s)

    # prepare initial guess.
    N_vars = length(Œ≤_initial)

    # set up cost function.
    f = bb->evalcLŒ≤costfunc(bb, Œ±s, Œª, Œ©s, U, S_U)

    #df_Euc = aa->ForwardDiff.gradient(f, aa)
    Œ≤s, ‚àÇùìõ_‚àÇŒ≤_eval, diff = setupcLŒ≤ùìõ(L, length(S_U), one(T))
    df_Euc = bb->evalcLŒ≤costfuncgradient!(Œ≤s, ‚àÇùìõ_‚àÇŒ≤_eval, diff,
                            bb,
                            Œ±s,
                            Œª,
                            Œ©s,
                            U,
                            S_U)

    # tell optimizer to use hessian approx.
    H = zeros(T, N_vars, N_vars)

    # retraction.
    ‚Ñú = circleretractionwithproject

    ## configuration for the trust-region subproblem.
    TR_config = TrustRegionConfigType(  minimum_TR_radius,
                                        maximum_TR_radius,
                                        max_iter_tCG,
                                        verbose_flag,
                                        œÅ_lower_acceptance,
                                        œÅ_upper_acceptance)

    opt_config = OptimizationConfigType( max_iter,
                                            verbose_flag,
                                            norm_df_tol,
                                            objective_tol,
                                            avg_Œîf_tol,
                                            avg_Œîf_window,
                                            max_idle_update_count,
                                            ùëü )

    ## Run scheme.
    p_star, f_p_array, norm_df_array,
        num_iters = engineArray(f,
                            df_Euc,
                            Œ≤_initial,
                            copy(Œ≤_initial),
                            TR_config,
                            opt_config,
                            H,
                            ‚Ñú;
                            ùëî = g)
    #
    return p_star, f_p_array, norm_df_array, num_iters
end


function solvecLŒ≤problemPSO( Œ©s::Vector{T},
                            Œª::T,
                            Œ±s::Vector{T},
                            S_U::Vector{Complex{T}},
                            U,
                            Œ≤_initial::Vector{T};
                            max_iters_PSO::Int = 90,
                            N_epochs::Int = 3,
                            N_particles = 3,
                            œµ_retraction = 1e-9,
                            verbose_flag::Bool = false) where T <: Real

    # set up.
    L = length(Œ≤_initial)
    @assert length(Œ©s) == L == length(Œ±s)

    # prepare initial guess.
    N_vars = length(Œ≤_initial)

    # set up cost function.
    f = bb->evalcLŒ≤costfunc(bb, Œ±s, Œª, Œ©s, U, S_U)

    # retraction.
    ‚Ñú = circleretractionwithproject

    # set up PSO's objective function.
    p_persist = copy(Œ≤_initial)
    costfunc = XX->f(‚Ñú(p_persist, XX, one(T)))

    # initial guess.
    x0 = zeros(T, length(Œ≤_initial))

    for n = 1:N_epochs

        # initial guess is all zeros.
        fill!(x0, zero(T))

        # optimize for the tangent vector that yields the least cost.
        # Unconstrained optimization.
        op = Optim.Options( iterations = max_iters_PSO,
                                 store_trace = false,
                                 show_trace = verbose_flag)

        swarm = Optim.ParticleSwarm(; lower = [],
                        upper = [],
                        n_particles = N_particles)
        #
        results = Optim.optimize(costfunc,
                        x0, swarm, op)

        x_star = results.minimizer
        p_persist[:] = ‚Ñú(p_persist, x_star, one(T))
    end

    return p_persist
end
