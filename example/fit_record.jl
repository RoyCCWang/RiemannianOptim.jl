## test opt

using BenchmarkTools

import Random
import PyPlot
import Printf


import Statistics
import SpecialFunctions

import Calculus
import ForwardDiff

import Optim

using LinearAlgebra

import BSON

include("../src/problems/FID_helpers.jl")
include("../src/problems/FID_persist.jl")

include("../src/problems/FID_phase_helpers.jl")

include("../src/declarations.jl")

include("../src/retractions/Rp.jl")
include("../src/retractions/circular.jl")
include("../src/retractions/compositions.jl")
include("../src/retractions/interval.jl")

include("../src/manifold/vector_transport.jl")

include("../src/optimization/CG.jl")
include("../src/optimization/vectorspace/engine_array.jl")
include("../src/optimization/TRS/trustregion.jl")
include("../src/optimization/TRS/trhelpers.jl")

include("../src/problems/RKHS_positive_coefficients.jl")

include("../src/frontends/RKHS.jl")
include("../src/frontends/FID_FT.jl")
include("../src/frontends/FID_DTFT.jl")

include("../src/frontends/RKHS.jl")
include("../src/frontends/FID_FT.jl")
include("../src/frontends/FID_DTFT.jl")

PyPlot.close("all")

Random.seed!(25)

fig_num = 1

# # stress test.
# N_pairs = 55
# L = 110

## problematic case if no PSO.
N_pairs = 6
L = 11

# # odd L.
# N_pairs = 4
# L = 7
#
# # even L.
# N_pairs = 4
# L = 8

Œæs = sort(rand(L) .* 10.0)
Œªs = rand(L) .* 14.0
#Œ±s = rand(L) .* 21000.0 # trouble case. Need to crank up Œ±_max.
Œ±s = rand(L) .* 2100.0
Œ∫s = rand(L) .* 3100.0

#Œæs = -Œæs ./ Œ∫s
Œªs = Œªs ./ Œ∫s
Œªsc = Œªs[1] .* ones(L)

Œ±s = sort(Œ±s ./ Œ∫s, rev = true)
Œ±_values_oracle = Œ±s[1:N_pairs]
Œ±s_oracle = parseŒ±(Œ±_values_oracle, L)

Œ≤_oracle = projectcircle.( rand(L) .* (2*œÄ) )
#Œ≤_oracle = zeros(L)
p_oracle = [Œ±_values_oracle; Œ≤_oracle]

println("[Œ±s_oracle Œ≤_oracle Œªs Œæs] = ")
display([Œ±s_oracle Œ≤_oracle Œªs Œæs])
println()


## visualize.
S = pp->evalFIDFT(pp, Œ±s_oracle, Œ≤_oracle, Œªs, Œæs)
Sc = pp->evalFIDFT(pp, Œ±s_oracle, Œ≤_oracle, Œªsc, Œæs)

# eval.
N_viz = 1000
P = LinRange(0, 10.0, N_viz)

S_P = S.(P)
Sc_P = Sc.(P)

PyPlot.figure(fig_num)
fig_num += 1

PyPlot.plot(P, abs.(S_P), label = "abs.(S_P)")
PyPlot.plot(P, abs.(Sc_P), "--", label = "abs.(Sc_P)")

PyPlot.legend()
PyPlot.xlabel("Hz")
PyPlot.ylabel("linear amplitude unit")
PyPlot.title("DTFT of refined candidates")




##### solve.

# set up data.
N_ùìü = 200
ùìü = LinRange(0, 10, N_ùìü)
S_ùìü = S.(ùìü)


##### speed up gradient.

f = pp->evalFIDFTŒ±Œ≤costfunc(pp, Œªs, Œæs, ùìü, S_ùìü)
fslow = pp->evalFIDFTŒ±Œ≤costfuncslow(pp, Œªs, Œæs, ùìü, S_ùìü)

df_AD = aa->ForwardDiff.gradient(f, aa)

# #no pre-allocation.
# df_AN = pp->evalFIDFTŒ±Œ≤costfuncgradient(pp, Œªs, Œæs, ùìü, S_ùìü)

# with pre-allocation. Not much faster than the non-preallocated version.
Œ±s_persist, Œ≤s_persist, ‚àÇùìõ_‚àÇŒ≤_eval_persist, ‚àÇùìõ_‚àÇŒ±_eval_persist,
        ‚àÇùìõ_‚àÇa_eval_persist, diff_persist = setupFTFIDŒ±Œ≤ùìõ(N_pairs, L, length(S_ùìü), 1.0)

#
df_AN = pp->evalFIDFTŒ±Œ≤costfuncgradient!(Œ±s_persist,
                Œ≤s_persist, ‚àÇùìõ_‚àÇŒ≤_eval_persist,
                ‚àÇùìõ_‚àÇŒ±_eval_persist, ‚àÇùìõ_‚àÇa_eval_persist,
                diff_persist,
                pp, Œªs, Œæs, ùìü, S_ùìü)


p_test = rand(L + N_pairs)

println("Timing df_AN:")
@time df_AN(p_test)
@time df_AN(p_test)
@time df_AN(p_test)
println()

println("Timing AD:")
@time df_AD(p_test)
@time df_AD(p_test)
@time df_AD(p_test)
println()

df_AD_p0 = df_AD(p_test)
df_AN_p0 = df_AN(p_test)
#q = df_AD_p0[end-L+1:end]
q = df_AD_p0
discrepancy = norm(q-df_AN_p0)
println("discrepancy = ", discrepancy)
display([q df_AN_p0])
println()

#@assert 1==2



### retraction settings.
#Œ±_max = 500.0
Œ±_max = 10.0
œµ_retraction = 1e-9 # for intervalretraction.

# initial guess.
Œ±_values_initial = sort(rand(N_pairs), rev = true )
Œ≤_initial = rand(L)

# ## good.
# Œ±_values_initial = [     0.9553781538862007;
#                          0.8638975162587343;
#                          0.8007100409944219;
#                          0.3528806798699531;
#                          0.3099816588294799;
#                          0.20800886134956031]
# Œ≤_initial = [ 0.7914787386761699;
#                  0.6130379854906192;
#                  0.9149529050312983;
#                  0.09375968676995772;
#                  0.46501712469348533;
#                  0.1913590317184708;
#                  0.3470474144198672;
#                  0.9648255311678162;
#                  0.6128816366256244;
#                  0.04504530111973937;
#                  0.22437554345914945]


## bad.
# Œ±_values_initial = [    0.9173825816743866;
#                          0.7617216102778348;
#                          0.44667816154094053;
#                          0.2833106512893173;
#                          0.26719550327432295;
#                          0.14710489126440351]
# Œ≤_initial = [ 0.03274246945152992;
#                  0.05330532505475882;
#                  0.36859160530704904;
#                  0.899194597154837;
#                  0.8142417430874107;
#                  0.005779082024976345;
#                  0.16917199094824653;
#                  0.5187446766594683;
#                  0.00886028360812885;
#                  0.8146622549131075;
#                  0.05096339644377901]

import Optim

p_initial = [Œ±_values_initial; Œ≤_initial]

#p_cost = p_star
p_cost = p_initial

max_iters_PSO = 1000
N_particles = 3
println("Timing: PSO")
@time p_star_PSO = solveFIDFTŒ±Œ≤problemPSO(Œæs, Œªs, S_ùìü, ùìü, Œ±_values_initial,
                        Œ≤_initial;
                        max_iters_PSO = max_iters_PSO,
                        N_particles = N_particles,
                        œµ_retraction = œµ_retraction)

Œ±_star_PSO = p_star_PSO[1:length(Œ±_values_initial)]
Œ≤_star_PSO = p_star_PSO[end-length(Œ≤_initial)+1:end]


discrepancy = norm(p_oracle-p_star_PSO)
println("discrepancy between oracle and the final solution: ", discrepancy)
println("[p_oracle p_star_PSO]:")
display([p_oracle p_star_PSO])
println()




# Riemmian optim parameters.
verbose_flag = true
minimum_TR_radius = 1e-3

#max_iters_RMO = 5000
max_iters_RMO = 100


# solve.
@time p_star, f_p_array, norm_df_array,
        num_iters, f, df = solveFIDFTŒ±Œ≤problemRMO( Œæs,
                        Œªs,
                        S_ùìü,
                        ùìü,
                        Œ±_star_PSO,
                        Œ≤_star_PSO,
                        Œ±_max;
                        verbose_flag = verbose_flag,
                        max_iters_RMO = max_iters_RMO,
                        minimum_TR_radius = minimum_TR_radius,
                        œµ_retraction = œµ_retraction)


discrepancy = norm(p_oracle-p_star)
println("discrepancy between oracle and the solution: ", discrepancy)
println("[p_oracle p_star]:")
display([p_oracle p_star])
println()


# Visualize regression result.
PyPlot.figure(fig_num)
fig_num += 1

PyPlot.plot(collect(1:num_iters), log.(f_p_array))

title_string = "log f(p) history vs. iterations"
PyPlot.title(title_string)

println("f(p_star_PSO) = ", f(p_star_PSO))
println("f(p_star) = ", f(p_star))
println()




# TODO play with the riemannian metric for Œ± and Œ≤.



# hybrid between PSO and Riemannian manifold optimization.
